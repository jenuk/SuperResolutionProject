{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from facedataset import FaceDataset\n",
    "from metrics import psnr\n",
    "from layers import GaussianBlur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import Model\n",
    "from classic_model import Classic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_seeds():\n",
    "    random.seed(714)\n",
    "    np.random.seed(714)\n",
    "    torch.manual_seed(714)\n",
    "\n",
    "reset_seeds()\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "input_size = 32\n",
    "upscaling_factor = 8\n",
    "output_size = upscaling_factor*input_size\n",
    "use_gpu = torch.cuda.is_available()\n",
    "\n",
    "num_examples = 4 # number of examples printed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(name, upscaling_factor=2):\n",
    "    model = Model(upscaling_factor)\n",
    "    model.load_state_dict(torch.load(f\"weights/{name}.ckpt\", map_location=torch.device('cpu')))\n",
    "    if use_gpu:\n",
    "        model = model.cuda()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loads the model from `weights/`, name is filename and shot_name is used to save results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "name = \"model_crit_mse_reg_disc_32\"\n",
    "short_name = \"mse_disc\"\n",
    "# for chaining upscaling_factor may differ from the factor that needs to be given here\n",
    "model = load_model(name, upscaling_factor)\n",
    "\n",
    "# for comparison \n",
    "# name = \"\"\n",
    "# short_name = \"bicubic\"\n",
    "# model = Classic(output_size)\n",
    "\n",
    "\n",
    "model.eval()\n",
    "gb = GaussianBlur(3, 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FFHQ\n",
    "\n",
    "Evaluation on the FFHQ dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"data/small256x256\"\n",
    "test_set = FaceDataset(data_path, 65000, 70000, input_size, upscaling_factor, p_flip=0)\n",
    "test_loader = DataLoader(test_set, batch_size = batch_size, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"data/comp_test\"\n",
    "small_test_set = FaceDataset(data_path, 0, 100, input_size, upscaling_factor, p_flip=0)\n",
    "small_test_loader = DataLoader(test_set, batch_size = batch_size, shuffle=False, num_workers=4)\n",
    "# images without copyright"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class for chaining the model\n",
    "\n",
    "class MultiModel(nn.Module):\n",
    "    def __init__(self, model, amount):\n",
    "        \"\"\"\n",
    "        amount : int\n",
    "            how often to run model\n",
    "        \"\"\"\n",
    "        super(MultiModel, self).__init__()\n",
    "        \n",
    "        self.model = model\n",
    "        self.amount = amount\n",
    "        self.gb = GaussianBlur(3, 1.0, use_gpu)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = x\n",
    "        for i in range(self.amount-1):\n",
    "            out = self.model(out)\n",
    "            out = self.gb(out)\n",
    "        out = self.model(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi = MultiModel(model, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model):\n",
    "    \"\"\"\n",
    "    Evaluates model PSNR and SSIM on the complete test set.\n",
    "    \"\"\"\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        val_psnr = []\n",
    "        val_ssim = []\n",
    "\n",
    "        for img, target in tqdm(test_loader):\n",
    "            if use_gpu:\n",
    "                img = img.cuda()\n",
    "                target = target.cuda()\n",
    "            out = model(img)\n",
    "            val_psnr.append(psnr(out, target))\n",
    "            out = out.cpu().permute(0, 2, 3, 1).numpy()\n",
    "            target = target.cpu().permute(0, 2, 3, 1).numpy()\n",
    "            for i in range(out.shape[0]):\n",
    "                val_ssim.append(ssim(out[i], target[i], data_range=1, multichannel=True))\n",
    "\n",
    "\n",
    "        val_psnr = torch.cat(val_psnr)\n",
    "        val_ssim = torch.tensor(val_ssim)\n",
    "\n",
    "    print(f\"Mean PSNR {torch.mean(val_psnr):.2f} ± {torch.std(val_psnr):.2f}\")\n",
    "    print(f\"Mean SSIM {torch.mean(val_ssim):.3f} ± {torch.std(val_ssim):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eval_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saves the results of all upscalings on the small test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for k, (img, target) in tqdm(enumerate(small_test_loader), total=len(small_test_loader)):\n",
    "        out = torch.clamp(model(img), 0, 1)\n",
    "        psnrs = psnr(out, target)\n",
    "        for i in range(batch_size):\n",
    "            out_np = out[i].permute(1,2,0).numpy()\n",
    "            target_np = target[i].permute(1,2,0).numpy()\n",
    "            ssim_img = ssim(out_np, target_np, data_range=1, multichannel=True)\n",
    "            img_pil = transforms.functional.to_pil_image(img[i])\n",
    "            img_pil.save(f\"results/{upscaling_factor}x/low_{k*batch_size+i}.png\")\n",
    "            target_pil = transforms.functional.to_pil_image(target[i])\n",
    "            target_pil.save(f\"results/{upscaling_factor}x/high_{k*batch_size+i}.png\")\n",
    "            out_pil = transforms.functional.to_pil_image(out[i])\n",
    "            out_pil.save(f\"results/{upscaling_factor}x/{short_name}_{k*batch_size+i}.png\")\n",
    "            with open(f\"results/{upscaling_factor}x/{short_name}_{k*batch_size+i}.tex\", \"w\") as file:\n",
    "                file.write(rf\"PSNR: {psnrs[i]:.2f}\\\\\" + f\"\\nSSIM: {ssim_img:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b1 = (70, 90, 110, 130)\n",
    "b2 = (60, 160, 100, 200)\n",
    "for fn in [short_name, \"low\", \"high\"]:\n",
    "    img = Image.open(f\"results/{upscaling_factor}x/{fn}_29.png\").resize((upscaling_factor*input_size, upscaling_factor*input_size))\n",
    "    img.crop(b1).save(f\"results/{upscaling_factor}x/crops/{fn}1_29.png\")\n",
    "    img.crop(b2).save(f\"results/{upscaling_factor}x/crops/{fn}2_29.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set 5 & 14\n",
    " \n",
    "To evaluate performance on set 5 and 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"Set5\")\n",
    "# os.chdir(\"Set14\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    val_psnr = []\n",
    "    val_ssim = []\n",
    "\n",
    "    for fn in os.listdir():\n",
    "        target = transforms.functional.to_tensor(Image.open(fn)).unsqueeze(0)\n",
    "        \n",
    "        # the following images have an uneven size, which can not be halved\n",
    "        # so the last row/column is chopped off\n",
    "        if fn == \"comic.png\" or fn==\"zebra.png\":\n",
    "            target = target[:,:,:-1,:]\n",
    "        if fn == \"ppt3.png\":\n",
    "            target = target[:,:,:,:-1]\n",
    "        img = gb(target)[:,:,::2,::2]\n",
    "\n",
    "        if use_gpu:\n",
    "            img = img.cuda()\n",
    "            target = target.cuda()\n",
    "        #out = model(img)\n",
    "        out = transforms.functional.to_pil_image(img.squeeze())\n",
    "        out = out.resize((out.size[0]*2, out.size[1]*2), 3)\n",
    "        out = transforms.functional.to_tensor(out).unsqueeze(0)\n",
    "        val_psnr.append(psnr(out, target))\n",
    "        out = out.cpu().permute(0, 2, 3, 1).numpy()\n",
    "        target = target.cpu().permute(0, 2, 3, 1).numpy()\n",
    "        for i in range(out.shape[0]):\n",
    "            val_ssim.append(ssim(out[i], target[i], data_range=1, multichannel=True))\n",
    "\n",
    "\n",
    "    val_psnr = torch.cat(val_psnr)\n",
    "    val_ssim = torch.tensor(val_ssim)\n",
    "\n",
    "    print(f\"Mean PSNR {torch.mean(val_psnr):.2f} ± {torch.std(val_psnr):.2f}\")\n",
    "    print(f\"Mean SSIM {torch.mean(val_ssim):.3f} ± {torch.std(val_ssim):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../Set14\")\n",
    "# os.chdir(\"../Set5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del target"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
